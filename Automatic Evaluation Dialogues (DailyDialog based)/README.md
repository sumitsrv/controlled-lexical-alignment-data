# Supplementary Material: Generated Dialogues Dataset

This supplementary material contains the dialogues generated by different conversational language models for studying lexical alignment in human-agent conversations.

## Overview

This dataset comprises **10,545 dialogues** generated across four different conversational AI models, using various alignment weight configurations to control lexical alignment behavior.

### Data Source and Modification

These dialogues are **modified versions of a subset of the [DailyDialog dataset](https://aclanthology.org/I17-1099/)**. The modification process is as follows:

1. **First three turns**: Retained exactly as in the original DailyDialog source dialogues
2. **Fourth turn onwards (Speaker 2/Agent)**: Generated by an LLM-based utterance generator model with varying alignment weights
3. **All Speaker 1 (Human) turns**: Retained exactly as in the original DailyDialog source dialogues

This setup allows us to study how different generator models and alignment weight configurations affect the lexical alignment behavior of conversational agents while maintaining consistent human-side utterances.

### Models Included

| Model | Source | Dialogues |
|-------|--------|-----------|
| BlenderBot-3B | facebook/blenderbot-3B | 1,425 |
| DialoGPT-small | microsoft/DialoGPT-small | 1,330 |
| Llama-2-7b-chat | meta-llama/Llama-2-7b-chat-hf | 3,895 |
| Phi-3.5-mini-instruct | microsoft/Phi-3.5-mini-instruct | 3,895 |

## Directory Structure

```
supplementary_dialogues/
├── README.md                          # This file
├── alignment_data_20250329.tsv        # Aggregated alignment metrics for all dialogues
└── models/
    ├── BlenderBot-3B/
    │   ├── 25w/                       # Weight = 25
    │   │   ├── 0/                     # Dialogue index
    │   │   │   ├── dialogue.txt       # The generated dialogue
    │   │   │   └── output/            # Computed alignment metrics
    │   │   ├── 1/
    │   │   └── ...
    │   ├── 75w/
    │   └── ...
    ├── DialoGPT-small/
    ├── Llama-2-7b-chat/
    └── Phi-3.5-mini-instruct/
```

## Configuration Parameters

### Weight Values
The weight directories (e.g., `25w`, `75w`) represent different alignment weight configurations:

| Weight | Description |
|--------|-------------|
| 25 | Low alignment weight |
| 75 | |
| 125 | |
| 175 | |
| 225 | |
| 275 | |
| 325 | |
| 375 | |
| 425 | |
| 475 | |
| 500 | Medium alignment weight |
| 625 | |
| 750 | |
| 875 | |
| 1000 | High alignment weight |

### Other Parameters
- **History length**: 6 turns used for context in generation
- **Top-k sampling**: k=20 for all dialogues

## File Descriptions

### dialogue.txt
Each `dialogue.txt` file contains a conversation between a human and an AI agent, formatted as:
```
Human 1:	 [Human utterance]          # From original DailyDialog
Human 2:	 [Agent response]           # Turn 1-3: From DailyDialog, Turn 4+: Generated
Human 1:	 [Human utterance]          # From original DailyDialog
...
```

**Speaker Roles:**
- **Human 1**: Human participant (all turns retained from original DailyDialog)
- **Human 2**: 
  - Turns 1-3: Original responses from DailyDialog
  - Turn 4 onwards: Generated by the LLM-based utterance generator model

### output/ Directory
Each dialogue has an associated `output/` folder containing computed alignment metrics:

| File | Description |
|------|-------------|
| `dialogue_txt-dialogue.txt` | Processed dialogue text |
| `dialogue_txt-lexicon.tsv` | Shared lexicon between speakers |
| `dialogue_txt-lexicon-self-rep-A.tsv` | Self-repetition lexicon for Human 1 |
| `dialogue_txt-lexicon-self-rep-B.tsv` | Self-repetition lexicon for Human 2 |
| `metrics-speaker-independent.tsv` | Overall dialogue-level metrics |
| `metrics-speaker-dependent.tsv` | Per-speaker alignment metrics |

### alignment_data_20250329.tsv
Aggregated alignment metrics for all dialogues with the following columns:

| Column | Description |
|--------|-------------|
| EV | Expression Variety |
| ER | Expression Repetition |
| Voc. Overlap | Vocabulary Overlap between speakers |
| ENTR | Entropy measure |
| S1, S2 | Speaker identifiers |
| IE_S1, IE_S2 | Initiated Expressions for each speaker |
| ER_S1, ER_S2 | Expression Repetition for each speaker |
| SR/S1/ER, SR/S2/ER | Self-repetition metrics |
| SR/S1/ENTR, SR/S2/ENTR | Self-repetition entropy |
| dialogue_count | Index of the dialogue |
| mname | Model name (HuggingFace format) |
| history_length | Context window size |
| num_samples | Number of samples generated |
| weight | Alignment weight parameter |
| topk | Top-k sampling parameter |

## Alignment Metrics

The following lexical alignment metrics are computed for each dialogue:

1. **Expression Variety (EV)**: Ratio of unique expressions to total expressions
2. **Expression Repetition (ER)**: Frequency of repeated expressions across speakers
3. **Vocabulary Overlap**: Proportion of shared vocabulary between speakers
4. **Entropy (ENTR)**: Lexical diversity measure
5. **Initiated Expression (IE)**: Expressions first introduced by a speaker
6. **Self-Repetition (SR)**: Within-speaker lexical repetition patterns
7. **L, LMAX**: Expression length statistics

## Usage

To load the aggregated metrics in Python:

```python
import pandas as pd

# Load all alignment metrics
df = pd.read_csv('alignment_data_20250329.tsv', sep='\t')

# Filter by model
blenderbot_df = df[df['mname'] == 'facebook/blenderbot-3B']

# Filter by weight
low_weight_df = df[df['weight'] == 25]
high_weight_df = df[df['weight'] == 1000]
```

To read individual dialogues:

```python
import os

base_path = 'models/BlenderBot-3B/500w/0'

# Read dialogue
with open(os.path.join(base_path, 'dialogue.txt'), 'r') as f:
    dialogue = f.read()

# Read metrics
metrics = pd.read_csv(
    os.path.join(base_path, 'output/metrics-speaker-dependent.tsv'), 
    sep='\t'
)
```

## Citation

If you use this dataset in your research, please cite our paper (citation details will be added upon publication).

## License

This dataset is provided for research purposes. Please refer to the main repository license for terms of use.

## Contact

For questions regarding this dataset, please refer to the corresponding author information in the associated paper.
